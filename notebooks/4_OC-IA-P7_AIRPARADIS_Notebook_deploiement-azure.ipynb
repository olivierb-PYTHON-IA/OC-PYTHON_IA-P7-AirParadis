{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b26306a9",
   "metadata": {},
   "source": [
    "# OpenClassrooms - Ingenieur IA\n",
    "# Projet 7 - AirParadis\n",
    "# Détectez les Bad Buzz grâce au Deep Learning\n",
    "\n",
    "## Objectif du projet : \n",
    "- **Développer le prototype d’un produit IA permettant de prédire le sentiment associé à un tweet**\n",
    "\n",
    "## Trois approches :\n",
    "- **Approche 1 : 'API sur étagère' en utilisant l’API du service cognitif proposé par Microsoft Azure pour l’analyse de sentiment**\n",
    "- **Approche 2 : 'Modèle sur mesure simple' en utilisant le service Azure Machine Learning Studio**\n",
    "- **Approche 3 : 'Modèle sur mesure avancé' en utilisant le service Azure Machine Learning pour développer un modèle basé sur des réseaux de neurones profonds pour prédire le sentiment associé à un tweet**\n",
    "\n",
    "## Plan - Approche 3 : 'Modèle sur mesure avancé' :\n",
    "- **Déploiement dans Azure**\n",
    "    - Récupération du workspace Azure ML\n",
    "    - Récupération du modèle de Azure ML\n",
    "    - Création du fichier score.py\n",
    "    - Configuration de l'environnement d'éxécution\n",
    "    - Configuration de l'inférence\n",
    "    - Déploiement en local\n",
    "    - Déploiement en remote\n",
    "- **Prototype permettant de prédire le sentiment associé à un tweet**\n",
    "    - Fonction 'prototype'\n",
    "    - Test du déploiement dans Azure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ec69606",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from keras_preprocessing.text import tokenizer_from_json\n",
    "\n",
    "from azureml.core.model import Model\n",
    "from azureml.core.environment import Environment\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.webservice import AciWebservice\n",
    "from azureml.core import Workspace\n",
    "from azureml.core import Webservice\n",
    "from azureml.core.webservice import LocalWebservice\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4eea23d",
   "metadata": {},
   "source": [
    "# Déploiement dans Azure "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154a048c",
   "metadata": {},
   "source": [
    "## Récupération du workspace Azure ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ef68ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "azure_subscription_id = os.environ['AZURE_SUBSCRIPTION_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18d0af70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Falling back to use azure cli login credentials.\n",
      "If you run your code in unattended mode, i.e., where you can't give a user input, then we recommend to use ServicePrincipalAuthentication or MsiAuthentication.\n",
      "Please refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\n"
     ]
    }
   ],
   "source": [
    "ws = Workspace(subscription_id=azure_subscription_id,\n",
    "              resource_group=\"OC-IA-P7\",\n",
    "              workspace_name=\"ws-OC-P7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701729a1",
   "metadata": {},
   "source": [
    "## Récupération du modèle de Azure ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10182de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_azure = 'Best_Model_AirParadis_h5'\n",
    "model_azure = Model(ws, model_name_azure)\n",
    "model_path_azure = model_azure.download(exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1fcf8a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(workspace=Workspace.create(name='ws-OC-P7', subscription_id='dc0050bb-8e50-4b60-8aac-034371ba1a2a', resource_group='OC-IA-P7'), name=Best_Model_AirParadis_h5, id=Best_Model_AirParadis_h5:1, version=1, tags={}, properties={})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_azure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fd5dc1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'airparadis_best_model.h5'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path_azure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f83e9c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "model_keras = load_model(model_path_azure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03ec9248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 24, 100)           3606300   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 24, 100)           0         \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (None, 50)                22800     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 3,629,151\n",
      "Trainable params: 22,851\n",
      "Non-trainable params: 3,606,300\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_keras.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1110a71f",
   "metadata": {},
   "source": [
    "##### Remarque :\n",
    "- Le modèle a été enregistré dans les modèles Azure avec le code suivant :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "527d3126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmodel = Model.register(model_path = \"airparadis_best_model.h5\",\\n                       model_name = \"Best_Model_AirParadis_h5\",\\n                       description = \"Best model for AirParadis\",\\n                       workspace = ws)\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "model = Model.register(model_path = \"airparadis_best_model.h5\",\n",
    "                       model_name = \"Best_Model_AirParadis_h5\",\n",
    "                       description = \"Best model for AirParadis\",\n",
    "                       workspace = ws)\n",
    "\"\"\"                       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1820ec39",
   "metadata": {},
   "source": [
    "## Création du fichier score.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "725d9bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile score.py\n",
    "import numpy as np\n",
    "import preprocessor as tweetpreprocessor\n",
    "\n",
    "import tensorflow\n",
    "from keras_preprocessing.text import tokenizer_from_json\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "from azureml.core.model import Model\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    model_path = Model.get_model_path(model_name = 'Best_Model_AirParadis_h5')\n",
    "    model = load_model(model_path)\n",
    "\n",
    "def run(request):\n",
    "    tweet_request = json.loads(request)[\"tweet\"]\n",
    "    X_test_pad = preprocess(tweet_request)\n",
    "    y_pred = model.predict(X_test_pad)\n",
    "    y_pred_classe = np.where(y_pred>0.5, \"positive\", \"negative\")\n",
    "\n",
    "    return f\"Sentiment is : {y_pred_classe} - score = {y_pred}\"\n",
    "\n",
    "def preprocess(tweet):\n",
    "    tweet_clean = tweetpreprocessor.clean(tweet)\n",
    "    \n",
    "    connect_str = os.getenv('AZURE_STORAGE_CONNECTION_STRING')\n",
    "    blob_service_client = BlobServiceClient.from_connection_string(connect_str)\n",
    "    blob_client = blob_service_client.get_blob_client(container=\"airparadiscontainer\", blob='tokenizer.json')\n",
    "    \n",
    "    with open('tokenizer.json', \"wb\") as download_file:\n",
    "        download_file.write(blob_client.download_blob().readall())\n",
    "    \n",
    "    with open('tokenizer.json') as f:\n",
    "        data = json.load(f)\n",
    "        tokenizer = tokenizer_from_json(data)\n",
    "    \n",
    "    MAX_WORD_LENGTH = 24\n",
    "    trunc_type='post'\n",
    "    padding_type='post'\n",
    "    \n",
    "    tweet_clean_sequence = tokenizer.texts_to_sequences([tweet_clean])\n",
    "    tweet_clean_pad = pad_sequences(tweet_clean_sequence, maxlen=MAX_WORD_LENGTH, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "    return tweet_clean_pad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd2e343",
   "metadata": {},
   "source": [
    "##### Remarque :\n",
    "- Le tokenizer a été enregistré dans le service de stockage Azure Blob avec le code suivant :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ff698a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom azure.storage.blob import BlobServiceClient\\n    \\n# 1 - Récupération de la chaine de connection au service dans les variables d\\'environnement\\nconnect_str = os.getenv(\\'AZURE_STORAGE_CONNECTION_STRING\\')\\n\\n# 2 - Création d\\'un client pour accéder au service de stockage Azure Blob\\nblob_service_client = BlobServiceClient.from_connection_string(connect_str)\\n\\n# 3 - Upload du token dans le service de stockage\\nblob_client = blob_service_client.get_blob_client(container=\"airparadiscontainer\", blob=\\'tokenizer.json\\')\\nwith open(\\'tokenizer.json\\', \"rb\") as data:\\n    blob_client.upload_blob(data)\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "    \n",
    "# 1 - Récupération de la chaine de connection au service dans les variables d'environnement\n",
    "connect_str = os.getenv('AZURE_STORAGE_CONNECTION_STRING')\n",
    "\n",
    "# 2 - Création d'un client pour accéder au service de stockage Azure Blob\n",
    "blob_service_client = BlobServiceClient.from_connection_string(connect_str)\n",
    "\n",
    "# 3 - Upload du token dans le service de stockage\n",
    "blob_client = blob_service_client.get_blob_client(container=\"airparadiscontainer\", blob='tokenizer.json')\n",
    "with open('tokenizer.json', \"rb\") as data:\n",
    "    blob_client.upload_blob(data)\n",
    "\"\"\"    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec88c737",
   "metadata": {},
   "source": [
    "## Configuration de l'environnement d'éxécution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b08b001",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Environment(\"myenv\")\n",
    "python_packages = ['numpy', 'tensorflow','azureml-core', 'keras', 'tweet-preprocessor', 'azure-storage-blob']\n",
    "for package in python_packages:\n",
    "    env.python.conda_dependencies.add_pip_package(package)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5c3ff1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "connect_str = os.getenv('AZURE_STORAGE_CONNECTION_STRING')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5e274fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.environment_variables = {\"AZURE_STORAGE_CONNECTION_STRING\":connect_str}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea2e955",
   "metadata": {},
   "source": [
    "## Configuration de l'inférence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd64b575",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_config = InferenceConfig(environment= env, entry_script= \"score.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e143a4",
   "metadata": {},
   "source": [
    "## Déploiement en local"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9024e320",
   "metadata": {},
   "source": [
    "##### Remarque :\n",
    "- Code à décommenter pour un déploiement en local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca2c4818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndeployment_config_local = LocalWebservice.deploy_configuration(port=6789)\\n\\nservice_local = Model.deploy(ws, 'airparadisdeploymentlocal', [model_azure], inference_config, deployment_config_local)\\n\\nservice_local.wait_for_deployment(show_output = True)\\nprint(service_local.state)\\n\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "deployment_config_local = LocalWebservice.deploy_configuration(port=6789)\n",
    "\n",
    "service_local = Model.deploy(ws, 'airparadisdeploymentlocal', [model_azure], inference_config, deployment_config_local)\n",
    "\n",
    "service_local.wait_for_deployment(show_output = True)\n",
    "print(service_local.state)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf1cd66",
   "metadata": {},
   "source": [
    "## Déploiement en remote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36689894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running\n",
      "2021-08-24 15:30:13+02:00 Creating Container Registry if not exists.\n",
      "2021-08-24 15:30:13+02:00 Registering the environment.\n",
      "2021-08-24 15:30:15+02:00 Use the existing image.\n",
      "2021-08-24 15:30:16+02:00 Generating deployment configuration.\n",
      "2021-08-24 15:30:16+02:00 Submitting deployment to compute.\n",
      "2021-08-24 15:30:21+02:00 Checking the status of deployment airparadisdeployment3..\n",
      "2021-08-24 15:33:06+02:00 Checking the status of inference endpoint airparadisdeployment3.\n",
      "Succeeded\n",
      "ACI service creation operation finished, operation \"Succeeded\"\n",
      "Healthy\n"
     ]
    }
   ],
   "source": [
    "deployment_config_remote = AciWebservice.deploy_configuration(cpu_cores = 1, memory_gb = 1, description = 'AirParadis Deployment')\n",
    "\n",
    "service_remote = Model.deploy(ws, 'airparadisdeployment3', [model_azure], inference_config, deployment_config_remote)\n",
    "\n",
    "service_remote.wait_for_deployment(show_output = True)\n",
    "print(service_remote.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10186d94",
   "metadata": {},
   "source": [
    "# Prototype permettant de prédire le sentiment associé à un tweet\n",
    "- Ce prototype permet de prédire le sentiment associé à un tweet en utilisant le modèle sur mesure avancé déployé en remote dans Azure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1d66f3",
   "metadata": {},
   "source": [
    "## Fonction 'prototype' :\n",
    "- prend en argument un Tweet\n",
    "- renvoie la prédiction du sentiment et le score de probabilité associé au Tweet en entrée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8eafffa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(tweet):\n",
    "    # 1 - On récupère l'URI du service\n",
    "    service = Webservice(workspace=ws, name=\"airparadisdeployment3\")\n",
    "    scoring_uri = service.scoring_uri\n",
    "\n",
    "    # 2 - On récupère la clé d'authentification dans les variables d'environnement\n",
    "    key = os.environ['KEY_AIRPARADIS']\n",
    "\n",
    "    # 3 - On prépare le header\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    headers[\"Authorization\"] = f\"Bearer {key}\"\n",
    "\n",
    "    # 4 - On envoie la requête et on récupère la réponse\n",
    "    data = {\"tweet\":tweet}\n",
    "    data = json.dumps(data)\n",
    "    resp = requests.post(scoring_uri, data=data, headers=headers)\n",
    "\n",
    "    # 5 - On affiche le résultat = sentiment ('positive' ou 'negative'), ainsi que le score correspondant\n",
    "    print(resp.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c278c6",
   "metadata": {},
   "source": [
    "## Test du déploiement dans Azure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96318d9e",
   "metadata": {},
   "source": [
    "#### Tests avec les mêmes Tweets que le modèle avancé développé avec Jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a2a0d7",
   "metadata": {},
   "source": [
    "##### Tweet positif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6e49530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Sentiment is : [['positive']] - score = [[0.9623542]]\"\n"
     ]
    }
   ],
   "source": [
    "get_sentiment(\"The service at AirParadis is good\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d923a6f",
   "metadata": {},
   "source": [
    "##### Tweet négatif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f324aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Sentiment is : [['negative']] - score = [[0.03483599]]\"\n"
     ]
    }
   ],
   "source": [
    "get_sentiment(\"The service at AirParadis is bad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c2d06d",
   "metadata": {},
   "source": [
    "##### Tweet neutre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "812dc62f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Sentiment is : [['negative']] - score = [[0.47108507]]\"\n"
     ]
    }
   ],
   "source": [
    "get_sentiment(\"The service at AirParadis is average\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de12aae3",
   "metadata": {},
   "source": [
    "#### Conclusion :\n",
    "- Le déploiement fonctionne\n",
    "- On retrouve bien les mêmes prédictions et les mêmes scores de probabilité qu'avec le modèle avancé du Jupyter Notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
